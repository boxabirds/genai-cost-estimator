[
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o",
        "Variant":"default",
        "Input Threshold":0,
        "Input":2.5,
        "Output":10.0,
        "Input Cached":1.25,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o",
        "Variant":"batch",
        "Input Threshold":0,
        "Input":1.25,
        "Output":5.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-2024-08-06",
        "Variant":"default",
        "Input Threshold":0,
        "Input":2.5,
        "Output":10.0,
        "Input Cached":1.25,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-2024-08-06",
        "Variant":"batch",
        "Input Threshold":0,
        "Input":1.25,
        "Output":5.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-audio-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":2.5,
        "Output":10.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-audio-preview-2024-10-01",
        "Variant":"default",
        "Input Threshold":0,
        "Input":2.5,
        "Output":10.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-audio-preview-2024-10-01",
        "Variant":"default",
        "Input Threshold":0,
        "Input":100.0,
        "Output":200.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-2024-05-13",
        "Variant":"default",
        "Input Threshold":0,
        "Input":5.0,
        "Output":15.0,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o",
        "Version":"gpt-4o-2024-05-13",
        "Variant":"batch",
        "Input Threshold":0,
        "Input":2.5,
        "Output":7.5,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o mini",
        "Version":"gpt-4o-mini",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.15,
        "Output":0.6,
        "Input Cached":0.075,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o mini",
        "Version":"gpt-4o-mini",
        "Variant":"batch",
        "Input Threshold":0,
        "Input":0.075,
        "Output":0.3,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o mini",
        "Version":"gpt-4o-mini--2024-07-18",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.15,
        "Output":0.6,
        "Input Cached":0.075,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"GPT-4o mini",
        "Version":"gpt-4o-mini--2024-07-18",
        "Variant":"batch",
        "Input Threshold":0,
        "Input":0.075,
        "Output":0.3,
        "Input Cached":null,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":null,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"OpenAI o1-preview",
        "Version":"o1-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":15.0,
        "Output":60.0,
        "Input Cached":7.5,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"OpenAI o1-preview",
        "Version":"o1-preview-2024-09-12",
        "Variant":"default",
        "Input Threshold":0,
        "Input":15.0,
        "Output":60.0,
        "Input Cached":7.5,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"OpenAI o1-mini",
        "Version":"o1-mini",
        "Variant":"default",
        "Input Threshold":0,
        "Input":3.0,
        "Output":12.0,
        "Input Cached":1.5,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"OpenAI",
        "Model Creator":"OpenAI",
        "Model":"OpenAI o1-mini",
        "Version":"o1-mini-2024-09-12",
        "Variant":"default",
        "Input Threshold":0,
        "Input":3.0,
        "Output":12.0,
        "Input Cached":1.5,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":128.0,
        "Input Cache Storage":0.0,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/openai.com\/api\/pricing\/",
        "Versions Page":"https:\/\/platform.openai.com\/docs\/models"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.01875,
        "Output":0.075,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.25,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.0375,
        "Output":0.075,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.25,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash-001",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.01875,
        "Output":0.075,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.25,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash-001",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.0375,
        "Output":0.075,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.25,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash-002",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.01875,
        "Output":0.075,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Flash",
        "Version":"gemini-1.5-flash-002",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.0375,
        "Output":0.075,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.3125,
        "Output":6.25,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.625,
        "Output":6.25,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro-001",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.3125,
        "Output":6.25,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro-001",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.625,
        "Output":6.25,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro-002",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.3125,
        "Output":6.25,
        "Input Cached":0.0046875,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Google",
        "Model Creator":"Google",
        "Model":"Gemini 1.5 Pro",
        "Version":"gemini-1.5-pro-002",
        "Variant":"default",
        "Input Threshold":128001,
        "Input":0.625,
        "Output":6.25,
        "Input Cached":0.009375,
        "Input Cache Threshold":0.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":1.125,
        "Output Cache":0.0,
        "Pricing Page":"https:\/\/cloud.google.com\/vertex-ai\/generative-ai\/pricing",
        "Versions Page":"https:\/\/ai.google.dev\/gemini-api\/docs\/models\/gemini"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3.5 Sonnet",
        "Version":"claude-3-5-sonnet-latest",
        "Variant":"default",
        "Input Threshold":0,
        "Input":3.0,
        "Output":15.0,
        "Input Cached":3.75,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3.5 Sonnet",
        "Version":"claude-3-5-sonnet-20241022",
        "Variant":"default",
        "Input Threshold":0,
        "Input":3.0,
        "Output":15.0,
        "Input Cached":3.75,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3.5 Haiku",
        "Version":"claude-3-5-haiku-latest",
        "Variant":"default",
        "Input Threshold":0,
        "Input":1.0,
        "Output":5.0,
        "Input Cached":1.25,
        "Input Cache Threshold":2048.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3.5 Haiku",
        "Version":"claude-3-5-haiku-20241022",
        "Variant":"default",
        "Input Threshold":0,
        "Input":1.0,
        "Output":5.0,
        "Input Cached":1.25,
        "Input Cache Threshold":2048.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3 Opus",
        "Version":"claude-3-opus-latest",
        "Variant":"default",
        "Input Threshold":0,
        "Input":15.0,
        "Output":75.0,
        "Input Cached":18.75,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3 Opus",
        "Version":"claude-3-opus-20240229",
        "Variant":"default",
        "Input Threshold":0,
        "Input":15.0,
        "Output":75.0,
        "Input Cached":18.75,
        "Input Cache Threshold":1024.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3 Haiku",
        "Version":"claude-3-haiku-latest",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.25,
        "Output":1.25,
        "Input Cached":0.3,
        "Input Cache Threshold":2048.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Anthropic",
        "Model Creator":"Anthropic",
        "Model":"Claude 3 Haiku",
        "Version":"claude-3-haiku-20240307",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.25,
        "Output":1.25,
        "Input Cached":0.3,
        "Input Cache Threshold":2048.0,
        "Input Cache Increment":1.0,
        "Input Cache Storage":0.0,
        "Output Cache":null,
        "Pricing Page":"https:\/\/docs.anthropic.com\/en\/docs\/about-claude\/models",
        "Versions Page":"https:\/\/docs.anthropic.com\/en\/docs\/build-with-claude\/prompt-caching"
    },
    {
        "API Provider":"Cohere",
        "Model Creator":"Cohere",
        "Model":"Command R+",
        "Version":"command-r-plus-08-2024",
        "Variant":"default",
        "Input Threshold":0,
        "Input":2.5,
        "Output":10.0,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/cohere.com\/pricing",
        "Versions Page":"https:\/\/docs.cohere.com\/v2\/docs\/models"
    },
    {
        "API Provider":"Cohere",
        "Model Creator":"Cohere",
        "Model":"Command R",
        "Version":"command-r-08-2024",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.15,
        "Output":0.6,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/cohere.com\/pricing",
        "Versions Page":"https:\/\/docs.cohere.com\/v2\/docs\/models"
    },
    {
        "API Provider":"Cohere",
        "Model Creator":"Cohere",
        "Model":"Command R",
        "Version":"command-r-08-2024",
        "Variant":"fine-tuned",
        "Input Threshold":0,
        "Input":0.3,
        "Output":1.2,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/cohere.com\/pricing",
        "Versions Page":"https:\/\/docs.cohere.com\/v2\/docs\/models"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3.2 1B (Preview) 8k",
        "Version":"llama-3.2-1b-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.04,
        "Output":0.04,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3.2 3B (Preview) 8k",
        "Version":"llama-3.2-3b-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.06,
        "Output":0.06,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3.1 70B Versatile 128k",
        "Version":"llama-3.1-70b-versatile",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.59,
        "Output":0.79,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3.1 8B Instant 128k",
        "Version":"llama-3.1-8b-instant",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.08,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3 70B 8k",
        "Version":"llama3-70b-8192",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.59,
        "Output":0.79,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3 8B 8k",
        "Version":"llama3-8b-8192",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.08,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Mistral",
        "Model":"Mixtral 8x7B Instruct 32k",
        "Version":"mixtral-8x7b-32768",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.24,
        "Output":0.24,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Google",
        "Model":"Gemma 7B 8k Instruct",
        "Version":"gemma-7b-it",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.07,
        "Output":0.07,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Google",
        "Model":"Gemma 2 9B 8k",
        "Version":"gemma2-9b-it",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.2,
        "Output":0.2,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3 Groq 70B Tool Use Preview 8k",
        "Version":"llama3-groq-70b-8192-tool-use-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.89,
        "Output":0.89,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama 3 Groq 8B Tool Use Preview 8k",
        "Version":"llama3-groq-8b-8192-tool-use-preview",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.19,
        "Output":0.19,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Groq.com",
        "Model Creator":"Meta",
        "Model":"Llama Guard 3 8B 8k",
        "Version":"llama-guard-3-8b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.2,
        "Output":0.2,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/console.groq.com\/docs\/models",
        "Versions Page":"https:\/\/groq.com\/pricing\/"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"IBM",
        "Model":"IBM Granite",
        "Version":"ibm-granite\/granite-20b-code-instruct-8k",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.1,
        "Output":0.5,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"IBM",
        "Model":"IBM Granite",
        "Version":"ibm-granite\/granite-3.0-2b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.03,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"IBM",
        "Model":"IBM Granite",
        "Version":"ibm-granite\/granite-3.0-8b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"IBM",
        "Model":"IBM Granite",
        "Version":"ibm-granite\/granite-8b-code-instruct-128k",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-13b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.1,
        "Output":0.5,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-13b-chat",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.1,
        "Output":0.5,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-70b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.65,
        "Output":2.75,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-70b-chat",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.65,
        "Output":2.75,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-7b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 2",
        "Version":"meta\/llama-2-7b-chat",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 3.1",
        "Version":"meta\/meta-llama-3.1-405b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":9.5,
        "Output":9.5,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 3",
        "Version":"meta\/meta-llama-3-70b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.65,
        "Output":2.75,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 3",
        "Version":"meta\/meta-llama-3-70b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.65,
        "Output":2.75,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 3",
        "Version":"meta\/meta-llama-3-8b",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Meta",
        "Model":"LLama 3",
        "Version":"meta\/meta-llama-3-8b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Mistral",
        "Model":"Mistral",
        "Version":"mistralai\/mistral-7b-instruct-v0.2",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Mistral",
        "Model":"Mistral",
        "Version":"mistralai\/mistral-7b-vo.1",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.05,
        "Output":0.25,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"Replicate.com",
        "Model Creator":"Mistral",
        "Model":"Mixtral",
        "Version":"mistralai\/mixtral-8x7b-instruct-v0.1",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.3,
        "Output":1.0,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/replicate.com\/pricing",
        "Versions Page":"https:\/\/replicate.com\/pricing"
    },
    {
        "API Provider":"OpenRouter",
        "Model Creator":"Alibaba Cloud",
        "Model":"Qwen 2.5",
        "Version":"qwen\/qwen-2.5-7b-instruct",
        "Variant":"default",
        "Input Threshold":0,
        "Input":0.27,
        "Output":0.27,
        "Input Cached":null,
        "Input Cache Threshold":null,
        "Input Cache Increment":null,
        "Input Cache Storage":null,
        "Output Cache":null,
        "Pricing Page":"https:\/\/openrouter.ai\/qwen\/qwen-2.5-7b-instruct\/api?utm_source=chatgpt.com",
        "Versions Page":"https:\/\/openrouter.ai\/qwen\/qwen-2.5-7b-instruct\/api?utm_source=chatgpt.com"
    }
]